{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00c32e-1252-44b2-843e-2d4280a35df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Model: Moderate Dementia vs Signs of mild Dementia\n",
    "#getting the data for the first model ready using DataLoader\n",
    "#add a few images for moderate but changing brightness\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "brightness_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.10),\n",
    "])\n",
    "\n",
    "input_dir = \"Processed_MRI_Data_For_Second_Model\"\n",
    "input_sub_dir = \"Signs_of_Moderate_Dimentia\"\n",
    "output_path = os.path.join(input_dir, input_sub_dir)\n",
    "\n",
    "for mri_image in os.listdir(output_path):\n",
    "    img_path = os.path.join(output_path, mri_image)\n",
    "    img = Image.open(img_path)  # Load image\n",
    "    changed_img1 = brightness_transform(img)\n",
    "    changed_img1.save(os.path.join(output_path, f\"{mri_image}_changed_brightness_1.jpg\"))\n",
    "    changed_img2 = brightness_transform(img)\n",
    "    changed_img2.save(os.path.join(output_path, f\"{mri_image}_changed_brightness_2.jpg\"))\n",
    "    #changed_img3 = brightness_transform(img)\n",
    "    #changed_img3.save(os.path.join(output_path, f\"{mri_image}_changed_brightness_3.jpg\"))\n",
    "    #changed_img4 = brightness_transform(img)\n",
    "    #changed_img4.save(os.path.join(output_path, f\"{mri_image}_changed_brightness_4.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c225b5b-f395-4e75-bc24-d6b744c777cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data ready using DataLoader \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n",
    "])\n",
    "dataset = datasets.ImageFolder(root=\"Processed_MRI_Data_For_Second_Model\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92154cbe-5ae8-4a2c-8e25-55f729dc5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in pretrained resnet50\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "res_net_model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50db44-fcbd-4034-aba2-808de644d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the training set and validation set, but for each batch, weight the images so that\n",
    "#we get close to an equal number of images of each class in each batch.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "train_indices, val_indices = train_test_split(np.arange(len(dataset)), test_size=0.30, stratify=dataset.targets)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "#get the count of each class\n",
    "class_counts = [0,0]\n",
    "for class_i in train_indices:\n",
    "    c_i = dataset.targets[class_i]\n",
    "    class_counts[c_i] += 1\n",
    "class_proportions = [1/class_counts[0] , 1/class_counts[1]]\n",
    "class_proportions = [prop * 100000 for prop in class_proportions]\n",
    "sample_weights = []\n",
    "for idx in train_indices:  # Iterate through the training indices\n",
    "    label = dataset.targets[idx]\n",
    "    sample_weights.append(class_proportions[0] if label == 0 else class_proportions[1])\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, sampler=sampler)\n",
    "#print(sample_weights)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 50, shuffle = False)\n",
    "\n",
    "num_batches_to_check = 10  # Number of batches you want to inspect\n",
    "\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    if i >= num_batches_to_check:\n",
    "        break\n",
    "    label_count = Counter(labels.tolist())  # Count the labels in the batch\n",
    "    print(f\"Batch {i + 1} label count:\", label_count)\n",
    "print(\"-----------------------------\")\n",
    "for i, (images, labels) in enumerate(eval_loader):\n",
    "    if i >= num_batches_to_check:\n",
    "        break\n",
    "    label_count = Counter(labels.tolist())  # Count the labels in the batch\n",
    "    print(f\"Batch {i + 1} label count:\", label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a944fb-7ce5-4fd6-9207-61d5601bfd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output layer\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "res_net_model.fc = torch.nn.Linear(res_net_model.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0385513-ac8a-46e6-93d7-d73430429776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function and the optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(res_net_model.parameters(), lr=0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13e937-c943-4cf2-a706-7c825fa681d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "num_ftrs = res_net_model.fc.in_features\n",
    "res_net_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),  # 50% Dropout to prevent overfitting\n",
    "    nn.Linear(num_ftrs, 2)  # Assuming 2 classes in your dataset\n",
    ")\n",
    "\n",
    "#begin forward and backwards propogation\n",
    "from collections import Counter\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    res_net_model.train()\n",
    "    running_loss = 0.0\n",
    "    #iterate through a batch\n",
    "    print(len(train_loader))\n",
    "    for ind, (inputs, labels) in enumerate(train_loader):\n",
    "        #print(ind)\n",
    "        optimizer.zero_grad() #zero out gradients\n",
    "        batch_outputs = res_net_model(inputs)\n",
    "        loss = criterion(batch_outputs, labels)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (ind + 1) % 10 == 0:\n",
    "            label_count = Counter(labels.tolist())  # Count the labels in the batch\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{ind+1}/{len(train_loader)}], Loss: {loss.item():.4f} label count: {label_count}\")\n",
    "        if(ind + 1) % 150 == 0:\n",
    "            torch.save(res_net_model.state_dict(), f\"Second_Model_checkpoint_step_{ind+1}.pth\")\n",
    "            print(\"Model weights saved\")            \n",
    "\n",
    "    #start evaluation\n",
    "    res_net_model.eval()\n",
    "    correct, total = 0 , 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            eval_outputs = res_net_model(inputs)\n",
    "            _, predicted = torch.max(eval_outputs, 1)  # Get predicted class\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "torch.save(res_net_model.state_dict(), \"progress_model_weights.pth\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a40cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9d4a8-cdac-469d-91cf-86913e59ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training algorithm I used while observing. Load in the weights previously gotten during the training. \n",
    "#train it, observe the loss each batch, every two batches, you can be asked to save the current weights.\n",
    "#This allows us to view the loss closely, and I believe this allows us to reach the global minimum faster.\n",
    "#add a drop out layer to prevent overfitting due to our unequal class sizes.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "num_ftrs = res_net_model.fc.in_features\n",
    "res_net_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),  # 50% Dropout to prevent overfitting\n",
    "    nn.Linear(num_ftrs, 2)  # Assuming 2 classes in your dataset\n",
    ")\n",
    "res_net_model.load_state_dict(torch.load(\"Second_Model_checkpoint_step_150.pth\"))\n",
    "#begin forward and backwards propogation\n",
    "from collections import Counter\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    res_net_model.train()\n",
    "    running_loss = 0.0\n",
    "    #iterate through a batch\n",
    "    print(len(train_loader))\n",
    "    for ind, (inputs, labels) in enumerate(train_loader):\n",
    "        #print(ind)\n",
    "        optimizer.zero_grad() #zero out gradients\n",
    "        batch_outputs = res_net_model(inputs)\n",
    "        loss = criterion(batch_outputs, labels)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        label_count = Counter(labels.tolist())\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{ind+1}/{len(train_loader)}], Loss: {loss.item():.4f} label count: {label_count}\")\n",
    "        if (ind + 1) % 10 == 0:\n",
    "            save = input(\"Save this model?\")\n",
    "            if save == \"y\":\n",
    "                torch.save(res_net_model.state_dict(), f\"NEWLY_SAVED_MODEL_2_Updated_checkpoint_step_{ind+1}.pth\")\n",
    "                print(\"Model weights saved\")                    \n",
    "\n",
    "    #start evaluation\n",
    "    res_net_model.eval()\n",
    "    correct, total = 0 , 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            eval_outputs = res_net_model(inputs)\n",
    "            _, predicted = torch.max(eval_outputs, 1)  # Get predicted class\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "torch.save(res_net_model.state_dict(), \"progress_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model weights\n",
    "res_net_model.load_state_dict(torch.load(\"NEWLY_SAVED_MODEL_2_Updated_checkpoint_step_40.pth\"))\n",
    "res_net_model.eval()\n",
    "correct, total = 0 , 0\n",
    "with torch.no_grad():\n",
    "    for ind, (inputs, labels) in enumerate(eval_loader):\n",
    "        eval_outputs = res_net_model(inputs)\n",
    "        _, predicted = torch.max(eval_outputs, 1)  # Get predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(f\"Batch {ind+1}: Accuracy: {correct / total} , {correct}: {total}\")\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
