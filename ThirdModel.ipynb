{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e833fda8-ec7f-43d8-82a3-8e3ddf050f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Signs_of_Mild_Dimentia', 'Signs_of_Very_Mild_Dementia']\n"
     ]
    }
   ],
   "source": [
    "#Third Model: Mild Dementia vs Signs of very mild Dementia\n",
    "#getting the data for the first model ready using DataLoader\n",
    "#add a few images for moderate but changing brightness \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n",
    "])\n",
    "dataset = datasets.ImageFolder(root=\"Processed_MRI_Data_For_Third_Model\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10d839-1bcf-47a2-b330-4a83f73cfcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holde\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\holde\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Bring in Resnet pretrained model\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "res_net_model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d61553-c6cd-4094-9e9a-9e4f4fb1da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 label count: Counter({1: 27, 0: 23})\n",
      "Batch 2 label count: Counter({0: 32, 1: 18})\n",
      "Batch 3 label count: Counter({0: 29, 1: 21})\n",
      "Batch 4 label count: Counter({0: 25, 1: 25})\n",
      "Batch 5 label count: Counter({1: 25, 0: 25})\n",
      "Batch 6 label count: Counter({1: 25, 0: 25})\n",
      "Batch 7 label count: Counter({0: 32, 1: 18})\n",
      "Batch 8 label count: Counter({1: 28, 0: 22})\n",
      "Batch 9 label count: Counter({1: 25, 0: 25})\n",
      "Batch 10 label count: Counter({1: 27, 0: 23})\n",
      "-----------------------------\n",
      "Batch 1 label count: Counter({1: 42, 0: 8})\n",
      "Batch 2 label count: Counter({1: 36, 0: 14})\n",
      "Batch 3 label count: Counter({1: 35, 0: 15})\n",
      "Batch 4 label count: Counter({1: 37, 0: 13})\n",
      "Batch 5 label count: Counter({1: 33, 0: 17})\n",
      "Batch 6 label count: Counter({1: 35, 0: 15})\n",
      "Batch 7 label count: Counter({1: 38, 0: 12})\n",
      "Batch 8 label count: Counter({1: 35, 0: 15})\n",
      "Batch 9 label count: Counter({1: 35, 0: 15})\n",
      "Batch 10 label count: Counter({1: 40, 0: 10})\n"
     ]
    }
   ],
   "source": [
    "#create the training set and validation set, but for each batch, weight the images so that\n",
    "#we get close to an equal number of images of each class in each batch.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "train_indices, val_indices = train_test_split(np.arange(len(dataset)), test_size=0.25, stratify=dataset.targets)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "#get the count of each class\n",
    "class_counts = [0,0]\n",
    "for class_i in train_indices:\n",
    "    c_i = dataset.targets[class_i]\n",
    "    class_counts[c_i] += 1\n",
    "class_proportions = [1/class_counts[0] , 1/class_counts[1]]\n",
    "class_proportions = [prop * 100000 for prop in class_proportions]\n",
    "sample_weights = []\n",
    "for idx in train_indices:  # Iterate through the training indices\n",
    "    label = dataset.targets[idx]\n",
    "    sample_weights.append(class_proportions[0] if label == 0 else class_proportions[1])\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, sampler=sampler)\n",
    "#print(sample_weights)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 50, shuffle = False)\n",
    "\n",
    "num_batches_to_check = 10  # Number of batches you want to inspect\n",
    "\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    if i >= num_batches_to_check:\n",
    "        break\n",
    "    label_count = Counter(labels.tolist())  # Count the labels in the batch\n",
    "    print(f\"Batch {i + 1} label count:\", label_count)\n",
    "print(\"-----------------------------\")\n",
    "for i, (images, labels) in enumerate(eval_loader):\n",
    "    if i >= num_batches_to_check:\n",
    "        break\n",
    "    label_count = Counter(labels.tolist())  # Count the labels in the batch\n",
    "    print(f\"Batch {i + 1} label count:\", label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1578a8-d412-4ca9-b165-b3dbbcbeb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add output layer\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "res_net_model.fc = torch.nn.Linear(res_net_model.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d44f06-9801-43f9-b671-21a518d10c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function and the optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(res_net_model.parameters(), lr=0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58e4ef-45de-46b2-901b-4bedf7487a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nimport torch.nn as nn\\nimport torchvision.models as models\\nnum_ftrs = res_net_model.fc.in_features\\nres_net_model.fc = nn.Sequential(\\n    nn.Dropout(p=0.4),  # 50% Dropout to prevent overfitting\\n    nn.Linear(num_ftrs, 2)  # Assuming 2 classes in your dataset\\n)\\n\\n#begin forward and backwards propogation\\nfrom collections import Counter\\nnum_epochs = 1\\nfor epoch in range(num_epochs):\\n    res_net_model.train()\\n    running_loss = 0.0\\n    #iterate through a batch\\n    print(len(train_loader))\\n    for ind, (inputs, labels) in enumerate(train_loader):\\n        #print(ind)\\n        optimizer.zero_grad() #zero out gradients\\n        batch_outputs = res_net_model(inputs)\\n        loss = criterion(batch_outputs, labels)\\n        loss.backward()  # Backpropagation\\n        optimizer.step()  # Update model weights\\n\\n        running_loss += loss.item()\\n        if (ind + 1) % 10 == 0:\\n            label_count = Counter(labels.tolist())  # Count the labels in the batch\\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{ind+1}/{len(train_loader)}], Loss: {loss.item():.4f} label count: {label_count}\")\\n        if((ind + 1) % 150 == 0 or (ind+1) % len(train_loader)==0):\\n            torch.save(res_net_model.state_dict(), f\"Third_Model_checkpoint_step_{ind+1}.pth\")\\n            print(\"Model weights saved\")            \\n\\n    #start evaluation\\n    res_net_model.eval()\\n    correct, total = 0 , 0\\n    with torch.no_grad():\\n        for inputs, labels in eval_loader:\\n            eval_outputs = res_net_model(inputs)\\n            _, predicted = torch.max(eval_outputs, 1)  # Get predicted class\\n            total += labels.size(0)\\n            correct += (predicted == labels).sum().item()\\n\\n    accuracy = 100 * correct / total\\n    print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\\n            \\ntorch.save(res_net_model.state_dict(), \"progress_model_weights.pth\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "num_ftrs = res_net_model.fc.in_features\n",
    "res_net_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),  # 50% Dropout to prevent overfitting\n",
    "    nn.Linear(num_ftrs, 2)  # Assuming 2 classes in your dataset\n",
    ")\n",
    "\n",
    "#begin forward and backwards propogation\n",
    "from collections import Counter\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    res_net_model.train()\n",
    "    running_loss = 0.0\n",
    "    #iterate through a batch\n",
    "    print(len(train_loader))\n",
    "    for ind, (inputs, labels) in enumerate(train_loader):\n",
    "        #print(ind)\n",
    "        optimizer.zero_grad() #zero out gradients\n",
    "        batch_outputs = res_net_model(inputs)\n",
    "        loss = criterion(batch_outputs, labels)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (ind + 1) % 10 == 0:\n",
    "            label_count = Counter(labels.tolist())  # Count the labels in the batch\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{ind+1}/{len(train_loader)}], Loss: {loss.item():.4f} label count: {label_count}\")\n",
    "        if((ind + 1) % 150 == 0 or (ind+1) % len(train_loader)==0):\n",
    "            torch.save(res_net_model.state_dict(), f\"Third_Model_checkpoint_step_{ind+1}.pth\")\n",
    "            print(\"Model weights saved\")            \n",
    "\n",
    "    #start evaluation\n",
    "    res_net_model.eval()\n",
    "    correct, total = 0 , 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            eval_outputs = res_net_model(inputs)\n",
    "            _, predicted = torch.max(eval_outputs, 1)  # Get predicted class\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "torch.save(res_net_model.state_dict(), \"progress_model_weights.pth\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba89082-6642-4dc1-81e2-3d7c9a82db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training algorithm I used while observing. Load in the weights previously gotten during the training. \n",
    "#train it, observe the loss each batch, every two batches, you can be asked to save the current weights.\n",
    "#This allows us to view the loss closely, and I believe this allows us to reach the global minimum faster.\n",
    "#add a drop out layer to prevent overfitting due to our unequal class sizes.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "num_ftrs = res_net_model.fc.in_features\n",
    "res_net_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),  # 50% Dropout to prevent overfitting\n",
    "    nn.Linear(num_ftrs, 2)  # Assuming 2 classes in your dataset\n",
    ")\n",
    "res_net_model.load_state_dict(torch.load(\"Third_Model_checkpoint_step_281.pth\"))\n",
    "from collections import Counter\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    res_net_model.train()\n",
    "    running_loss = 0.0\n",
    "    #iterate through a batch\n",
    "    print(len(train_loader))\n",
    "    for ind, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() #zero out gradients\n",
    "        batch_outputs = res_net_model(inputs)\n",
    "        loss = criterion(batch_outputs, labels)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        label_count = Counter(labels.tolist())  # Count the labels in the batch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{ind+1}/{len(train_loader)}], Loss: {loss.item():.5f} label count: {label_count}\")\n",
    "        if (ind + 1) % 20 == 0:\n",
    "            save = input(\"Save this model?\")\n",
    "            if save == \"y\":\n",
    "                torch.save(res_net_model.state_dict(), f\"NEWLY_SAVED_MODEL_3_Updated_checkpoint_step_{ind+1}.pth\")\n",
    "                print(\"Model weights saved\")            \n",
    "            \n",
    "\n",
    "            \n",
    "torch.save(res_net_model.state_dict(), \"progress_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model weights\n",
    "res_net_model.load_state_dict(torch.load(\"NEWLY_SAVED_MODEL_3_Updated_checkpoint_step_280.pth\"))\n",
    "res_net_model.eval()\n",
    "correct, total = 0 , 0\n",
    "with torch.no_grad():\n",
    "    for ind, (inputs, labels) in enumerate(eval_loader):\n",
    "        eval_outputs = res_net_model(inputs)\n",
    "        _, predicted = torch.max(eval_outputs, 1)  # Get predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(f\"Batch {ind+1}: Accuracy: {correct / total} , {correct}: {total}\")\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2c3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
